{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c6e25f9",
   "metadata": {},
   "source": [
    "# DS105 Intermediate Statistics  : Lesson Three - Chi Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a7e76a",
   "metadata": {},
   "source": [
    "### Table of Contents <a class=\"anchor\" id=\"DS105L3_toc\"></a>\n",
    "\n",
    "* [Table of Contents](#DS105L3_toc)\n",
    "    * [Page 1 - Introduction](#DS105L3_page_1)\n",
    "    * [Page 2 - One Proportion Testing](#DS105L3_page_2)\n",
    "    * [Page 3 - One Proportion Testing in Python](#DS105L3_page_3)\n",
    "    * [Page 4 - Two Proportion Testing](#DS105L3_page_4)\n",
    "    * [Page 5 - Two Proportion Testing in Python](#DS105L3_page_5)\n",
    "    * [Page 6 - Independent Chi-Squares in R](#DS105L3_page_6)\n",
    "    * [Page 7 - Goodness of Fit Chi-Squares in R](#DS105L3_page_7)\n",
    "    * [Page 8 - Goodness of Fit Chi-Squares in Python](#DS105L3_page_8)\n",
    "    * [Page 9 - McNemar Chi-Squares](#DS105L3_page_9)\n",
    "    * [Page 10 - McNemar Chi-Square Python](#DS105L3_page_10)\n",
    "    * [Page 11 - Key Terms](#DS105L3_page_11)\n",
    "    * [Page 12 - Lesson 3 Hands-On](#DS105L3_page_12)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe91c3c3",
   "metadata": {},
   "source": [
    "<hr style=\"height:10px;border-width:0;color:gray;background-color:gray\">\n",
    "\n",
    "# Page 1 - Introduction<a class=\"anchor\" id=\"DS105L3_page_1\"></a>\n",
    "\n",
    "[Back to Top](#DS105L3_toc)\n",
    "\n",
    "<hr style=\"height:10px;border-width:0;color:gray;background-color:gray\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ec0cf9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"720\"\n",
       "            height=\"480\"\n",
       "            src=\"https://player.vimeo.com/video/388619071\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.VimeoVideo at 0x7fdb304590a0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import VimeoVideo\n",
    "# Tutorial Video Name: Advanced Chi-Squares\n",
    "VimeoVideo('388619071', width=720, height=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da575f4c",
   "metadata": {},
   "source": [
    "The transcript for the above overview video **[is located here](https://repo.exeterlms.com/documents/V2/DataScience/Video-Transcripts/DSO105L03overview.zip)**.\n",
    "\n",
    "You have learned about the basic Chi-Square, which is called the Independent Chi-Square, but there are many more variations depending on your situation.  In this lesson, you will learn about proportion testing as well as some of the more advanced Chi-Squares you may want to employ in your arsenal. \n",
    "\n",
    "By the end of the lesson, you should be able to conduct the following in both Python and R: \n",
    "\n",
    "* One proportion tests\n",
    "* Two proportion tests\n",
    "* Independent Chi-Squares\n",
    "* Goodness of fit Chi-Squares\n",
    "* McNemar Chi-Squares\n",
    "\n",
    "In addition, you should also be able to: \n",
    "\n",
    "* Differentiate between the different types of categorical tests\n",
    "* Test assumptions and perform post hoc analysis for Chi-Squares in R\n",
    "\n",
    "This lesson will culminate in a hands on that will test your ability to differentiate and run the different categorical statistics using bank loan data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8306b75",
   "metadata": {},
   "source": [
    "<hr style=\"height:10px;border-width:0;color:gray;background-color:gray\">\n",
    "\n",
    "# Page 2 - One Proportion Testing<a class=\"anchor\" id=\"DS105L3_page_2\"></a>\n",
    "\n",
    "[Back to Top](#DS105L3_toc)\n",
    "\n",
    "<hr style=\"height:10px;border-width:0;color:gray;background-color:gray\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47bdc49",
   "metadata": {},
   "source": [
    "# One Proportion Testing\n",
    "\n",
    "One proportion testing is used when you want to see whether the proportion of two things are similar. \n",
    "\n",
    "---\n",
    "\n",
    "## One Proportion Testing in R\n",
    "\n",
    "As an example, you have an Easter basket full of candy, which is filled with both jellybeans and chocolate eggs. A random sample of 43 pieces of candy are taken from the Easter basket. There are 15 jellybeans and 28 chocolate eggs in the sample. You can use the function ```prop.test()``` to determine the probability that there are the same number of jellybeans as there are chocolates, meaning the proportion of jelly beans and chocolate eggs is equal to 0.5. To do this, you will use the argument ```x=``` to put in the number of jellybeans, and then the argument ```n=``` to specify the sample size. You can also use the argument ```alternative=``` to specify whether you want a one-tailed or two-tailed test. You will use the value “*two.sided*” for a two-tailed test since we want to determine if jellybeans and chocolates are equal or not equal. If you want to do a one-tailed test, you can use the values “*greater*” or “*less*”.\n",
    "\n",
    "\n",
    "\n",
    "```{r}\n",
    "prop.test(x = 15, n = 43, p = 0.5, alternative = \"two.sided\", correct = FALSE)\n",
    "```\n",
    "\n",
    "Here are the results from that: \n",
    "\n",
    "```text\n",
    "\t1-sample proportions test without continuity correction\n",
    "\n",
    "data:  15 out of 43, null probability 0.5\n",
    "X-squared = 3.9302, df = 1, p-value = 0.04743\n",
    "alternative hypothesis: true p is not equal to 0.5\n",
    "95 percent confidence interval:\n",
    " 0.2241859 0.4982822\n",
    "sample estimates:\n",
    "        p \n",
    "0.3488372 \n",
    "```\n",
    "\n",
    "The *p* value is .03, which means that the proportion of jelly beans to chocolate eggs is not equal, since it is different than .5 (half).  If you're wondering what the proportion of jelly beans is to the whole, it is found in the bottom on the ```sample estimates:```section: .34.  This means that your Easter basket contains about 35% jelly beans and about 65% chocolate eggs.  Hopefully you like chocolate!\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976f338b",
   "metadata": {},
   "source": [
    "<hr style=\"height:10px;border-width:0;color:gray;background-color:gray\">\n",
    "\n",
    "# Page 3 - One Proportion Testing in Python<a class=\"anchor\" id=\"DS105L3_page_3\"></a>\n",
    "\n",
    "[Back to Top](#DS105L3_toc)\n",
    "\n",
    "<hr style=\"height:10px;border-width:0;color:gray;background-color:gray\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0745d961",
   "metadata": {},
   "source": [
    "# One Proportion Testing in Python\n",
    "\n",
    "Now that you know how to do one proportion testing in R, you will try the exact same problem in Python, examining the proportion of jellybeans to chocolate eggs in your Easter basket when you have 15 jellybeans out of a total 43 pieces of candy in your randomly selected sample. \n",
    "\n",
    "You'll start by importing a few packages.  You'll need ```numpy``` as well as some specifics from ```statsmodels``` to do your one proportion *z* test.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "```\n",
    "\n",
    "Then you can define your ```count``` as the number of jelly beans, 15, and your ```nobs```, standing for the number of observations, as the total number of pieces of candy, which is 43.  You will also define the proportion ```value``` to which you want to compare.  Since you are trying to test whether the number of jelly beans is equal to the number of chocolate eggs, you will use a proportion of .5, which would be half and each would be equal.  Lastly you will define the output of your function ```proportions_ztest()``` as ```stat``` and ```pval```, and will feed into the ```proportions_ztest()``` function the arguments you just defined above: ```count```, ```nobs```, and ```value```. \n",
    "\n",
    "```python\n",
    "count = 15\n",
    "nobs = 43\n",
    "value = .5\n",
    "stat, pval = proportions_ztest(count, nobs, value)\n",
    "print(stat,pval)\n",
    "```\n",
    "\n",
    "Finally, go ahead and print your results! Although the decimal precision for the p-value is slightly different than in R, you still come to the same conclusion to reject to null hypothesis.\n",
    "\n",
    "```text\n",
    "-2.079806538622099 0.03754328113448803\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d22a76",
   "metadata": {},
   "source": [
    "<hr style=\"height:10px;border-width:0;color:gray;background-color:gray\">\n",
    "\n",
    "# Page 4 - Two Proportion Testing<a class=\"anchor\" id=\"DS105L3_page_4\"></a>\n",
    "\n",
    "[Back to Top](#DS105L3_toc)\n",
    "\n",
    "<hr style=\"height:10px;border-width:0;color:gray;background-color:gray\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ead44d5",
   "metadata": {},
   "source": [
    "# Two Proportion Testing\n",
    "\n",
    "You will use a two proportion *z* test when you want to compare the proportions of two different categories to the whole.\n",
    "\n",
    "---\n",
    "\n",
    "## Two Proportion Testing in R\n",
    "\n",
    "As an example, you will go back to your Easter basket full of candy, which is filled with both jelly beans and chocolate eggs.  Each are available in several colors, and With a two proportion test, you can determine whether the proportions of those candies to the whole differ, as well as whether the proportion of the pink candies differ. \n",
    "\n",
    "There are 15 jelly beans and 28 chocolate eggs. Of the jelly beans, 7 are pink.  Of the chocolate eggs, 12 are pink.\n",
    "\n",
    "You can again use the function ```prop.test()``` in R to test whether these are similar.  You'll use the argument ```x=``` to feed in a vector of your first two proportions. These will be the smaller part of the whole.  In this case, it's the number of candies from each type that are pink. \n",
    "\n",
    "Then you will feed in a argument of ```n=``` with the vector that includes the values of the total number of each type of candy. Lastly, you'll use the argument ```alternative=``` to choose whether you want a one-tailed or two-tailed test.  Just like the one proportion test, you can use the statement of ```two.sided```, ```greater```, and ```less``` which would be the possibilities for a one-tailed test.\n",
    "\n",
    "```{r}\n",
    "prop.test(x = c(7, 12), n = c(15, 28),\n",
    "          alternative = \"two.sided\")\n",
    "```\n",
    "\n",
    "Here is the output you will receive from the two proportion test: \n",
    "\n",
    "```text\n",
    "\t2-sample test for equality of proportions with continuity correction\n",
    "\n",
    "data:  c(7, 12) out of c(15, 28)\n",
    "X-squared = 7.5808e-32, df = 1, p-value = 1\n",
    "alternative hypothesis: two.sided\n",
    "95 percent confidence interval:\n",
    " -0.3119912  0.3881817\n",
    "sample estimates:\n",
    "   prop 1    prop 2 \n",
    "0.4666667 0.4285714 \n",
    "```\n",
    "\n",
    "The most important part of this output is the *p*-value. In this case, your *p*-value is 0.8105, which means that the sample gives evidence there is not a significant difference in the proportions of pink in either type of candy.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5599f53",
   "metadata": {},
   "source": [
    "<hr style=\"height:10px;border-width:0;color:gray;background-color:gray\">\n",
    "\n",
    "# Page 5 - Two Proportion Testing in Python<a class=\"anchor\" id=\"DS105L3_page_5\"></a>\n",
    "\n",
    "[Back to Top](#DS105L3_toc)\n",
    "\n",
    "<hr style=\"height:10px;border-width:0;color:gray;background-color:gray\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c762dc",
   "metadata": {},
   "source": [
    "# Two Proportion Testing in Python\n",
    "\n",
    "In order to complete two proportion testing in Python, you will use the same function, but will need to handle it a bit differently. \n",
    "\n",
    "For the Easter basket scenario from the last page, in which there are 15 jelly beans and 28 chocolate eggs, with 7 pink jelly beans and 12 pink chocolate eggs, here's what the Python code would look like:\n",
    "\n",
    "```python\n",
    "stat, pval = proportions_ztest([7, 12], [15, 28])\n",
    "print(stat,pval)\n",
    "```\n",
    "\n",
    "And here are the results you will obtain: \n",
    "\n",
    "```text\n",
    "0.23974366706563624 0.810528980523634\n",
    "```\n",
    "\n",
    "You see exactly the same statistical results as in R and that there is not a significant difference in the proportions of pink in either type of candy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f32112d",
   "metadata": {},
   "source": [
    "<hr style=\"height:10px;border-width:0;color:gray;background-color:gray\">\n",
    "\n",
    "# Page 6 - Independent Chi-Squares in R<a class=\"anchor\" id=\"DS105L3_page_6\"></a>\n",
    "\n",
    "[Back to Top](#DS105L3_toc)\n",
    "\n",
    "<hr style=\"height:10px;border-width:0;color:gray;background-color:gray\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f378ddb",
   "metadata": {},
   "source": [
    "# Independent Chi-Squares in R\n",
    "\n",
    "You recently learned how to conduct independent Chi-Squares in Python, and you already know how to compute them in MS Excel, so it's time to hit them up in R!\n",
    "\n",
    "---\n",
    "\n",
    "## Load Libraries\n",
    "\n",
    "In order to run independent Chi-Squares in R, you will need to install and load the library ```gmodels```.  \n",
    "\n",
    "```{r}\n",
    "install.packages(\"gmodels\")\n",
    "library(\"gmodels\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Load in Data\n",
    "\n",
    "Next, you will read in your data.  You'll be using **[survey data about the Star Wars movie franchise from over 1,000 participants](https://repo.exeterlms.com/documents/V2/DataScience/Intermediate-Stats/SW_survey_renamed.zip)**. This data, as the name suggests on the zip file, has had all the columns renamed for your ease of use.\n",
    "\n",
    "---\n",
    "\n",
    "## Question Set Up \n",
    "\n",
    "One of the quintessential debates in Star Wars fandom is whether you are a fan of episodes I, II, and III (the newer, second trilogy of movies) or a fan of episodes IV, V, and VI (the older, beginning trilogy of movies). In this Chi-Square, you will determine whether age category ```Age``` influences someone's ranking of Episode I: The Phantom Menace. \n",
    "\n",
    "---\n",
    "\n",
    "## Data Wrangling\n",
    "\n",
    "This data is already formatted correctly for an independent Chi-Square.\n",
    "\n",
    "---\n",
    "\n",
    "## Testing Assumptions and Running the Analysis \n",
    "\n",
    "There are two assumptions associated with independent Chi-Squares.  The first is that you need to have independent data. This is just a theoretical requirement - each person or object must be able to fit in only one cell.  The second is that your expected frequencies must be greater than 5 for each cell. You will be able to check this second assumption by running your Chi-Square and asking for expected frequencies.  \n",
    "\n",
    "You will use the ```CrossTable()``` function from the ```gmodels``` library, and specify your IV followed by your DV.  Then you can use the argument ```fisher=TRUE``` to specify that you want to use the Fisher's Exact Test method to calculate your effect size for Chi-Square, and the ```chisq=TRUE``` argument is to get the results from your Chi-Square.  The next argument is the one of two that are required to get your expected frequencies. ```expected=TRUE``` will provide the expected frequencies, but you also need to include ```format=\"SPSS\"``` to get them printed out! This format mimics the output you would receive if you used the statistical program SPSS.  \n",
    "\n",
    "The last argument is ```sresid=TRUE```, and this provides standardized residuals.  Those will be used for determining effect sizes later.\n",
    "\n",
    "```{r}\n",
    "CrossTable(SW_survey_renamed$Age, SW_survey_renamed$RankI, fisher=TRUE, chisq = TRUE, expected = TRUE, sresid=TRUE, format=\"SPSS\")\n",
    "```\n",
    "\n",
    "The output from this code is huge, since you have a number of different categories for each variable: \n",
    "\n",
    "```text\n",
    "\n",
    "   Cell Contents\n",
    "|-------------------------|\n",
    "|                   Count |\n",
    "|         Expected Values |\n",
    "| Chi-square contribution |\n",
    "|             Row Percent |\n",
    "|          Column Percent |\n",
    "|           Total Percent |\n",
    "|            Std Residual |\n",
    "|-------------------------|\n",
    "\n",
    "Total Observations in Table:  835 \n",
    "\n",
    "                      | SW_survey_renamed$RankI \n",
    "SW_survey_renamed$Age |        1  |        2  |        3  |        4  |        5  |        6  | Row Total | \n",
    "----------------------|-----------|-----------|-----------|-----------|-----------|-----------|-----------|\n",
    "                      |        6  |        0  |        2  |        4  |        1  |        3  |       16  | \n",
    "                      |    2.472  |    1.360  |    2.491  |    4.541  |    1.916  |    3.219  |           | \n",
    "                      |    5.036  |    1.360  |    0.097  |    0.065  |    0.438  |    0.015  |           | \n",
    "                      |   37.500% |    0.000% |   12.500% |   25.000% |    6.250% |   18.750% |    1.916% | \n",
    "                      |    4.651% |    0.000% |    1.538% |    1.688% |    1.000% |    1.786% |           | \n",
    "                      |    0.719% |    0.000% |    0.240% |    0.479% |    0.120% |    0.359% |           | \n",
    "                      |    2.244  |   -1.166  |   -0.311  |   -0.254  |   -0.662  |   -0.122  |           | \n",
    "----------------------|-----------|-----------|-----------|-----------|-----------|-----------|-----------|\n",
    "                 > 60 |       53  |       22  |       36  |       50  |       13  |       18  |      192  | \n",
    "                      |   29.662  |   16.326  |   29.892  |   54.496  |   22.994  |   38.630  |           | \n",
    "                      |   18.362  |    1.972  |    1.248  |    0.371  |    4.344  |   11.017  |           | \n",
    "                      |   27.604% |   11.458% |   18.750% |   26.042% |    6.771% |    9.375% |   22.994% | \n",
    "                      |   41.085% |   30.986% |   27.692% |   21.097% |   13.000% |   10.714% |           | \n",
    "                      |    6.347% |    2.635% |    4.311% |    5.988% |    1.557% |    2.156% |           | \n",
    "                      |    4.285  |    1.404  |    1.117  |   -0.609  |   -2.084  |   -3.319  |           | \n",
    "----------------------|-----------|-----------|-----------|-----------|-----------|-----------|-----------|\n",
    "                18-29 |       21  |       15  |       20  |       42  |       33  |       49  |      180  | \n",
    "                      |   27.808  |   15.305  |   28.024  |   51.090  |   21.557  |   36.216  |           | \n",
    "                      |    1.667  |    0.006  |    2.297  |    1.617  |    6.074  |    4.513  |           | \n",
    "                      |   11.667% |    8.333% |   11.111% |   23.333% |   18.333% |   27.222% |   21.557% | \n",
    "                      |   16.279% |   21.127% |   15.385% |   17.722% |   33.000% |   29.167% |           | \n",
    "                      |    2.515% |    1.796% |    2.395% |    5.030% |    3.952% |    5.868% |           | \n",
    "                      |   -1.291  |   -0.078  |   -1.516  |   -1.272  |    2.465  |    2.124  |           | \n",
    "----------------------|-----------|-----------|-----------|-----------|-----------|-----------|-----------|\n",
    "                30-44 |       15  |       11  |       28  |       57  |       25  |       71  |      207  | \n",
    "                      |   31.980  |   17.601  |   32.228  |   58.753  |   24.790  |   41.648  |           | \n",
    "                      |    9.015  |    2.476  |    0.555  |    0.052  |    0.002  |   20.686  |           | \n",
    "                      |    7.246% |    5.314% |   13.527% |   27.536% |   12.077% |   34.300% |   24.790% | \n",
    "                      |   11.628% |   15.493% |   21.538% |   24.051% |   25.000% |   42.262% |           | \n",
    "                      |    1.796% |    1.317% |    3.353% |    6.826% |    2.994% |    8.503% |           | \n",
    "                      |   -3.003  |   -1.573  |   -0.745  |   -0.229  |    0.042  |    4.548  |           | \n",
    "----------------------|-----------|-----------|-----------|-----------|-----------|-----------|-----------|\n",
    "                45-60 |       34  |       23  |       44  |       84  |       28  |       27  |      240  | \n",
    "                      |   37.078  |   20.407  |   37.365  |   68.120  |   28.743  |   48.287  |           | \n",
    "                      |    0.255  |    0.329  |    1.178  |    3.702  |    0.019  |    9.385  |           | \n",
    "                      |   14.167% |    9.583% |   18.333% |   35.000% |   11.667% |   11.250% |   28.743% | \n",
    "                      |   26.357% |   32.394% |   33.846% |   35.443% |   28.000% |   16.071% |           | \n",
    "                      |    4.072% |    2.754% |    5.269% |   10.060% |    3.353% |    3.234% |           | \n",
    "                      |   -0.505  |    0.574  |    1.085  |    1.924  |   -0.138  |   -3.063  |           | \n",
    "----------------------|-----------|-----------|-----------|-----------|-----------|-----------|-----------|\n",
    "         Column Total |      129  |       71  |      130  |      237  |      100  |      168  |      835  | \n",
    "                      |   15.449% |    8.503% |   15.569% |   28.383% |   11.976% |   20.120% |           | \n",
    "----------------------|-----------|-----------|-----------|-----------|-----------|-----------|-----------|\n",
    "\n",
    " \n",
    "Statistics for All Table Factors\n",
    "\n",
    "\n",
    "Pearson's Chi-squared test \n",
    "------------------------------------------------------------\n",
    "Chi^2 =  108.1543     d.f. =  20     p =  4.257807e-14 \n",
    "```\n",
    "\n",
    "The very first output provides you a guide to each individual cell. First you'll see the actual count, then you will see the expected values, then the Chi-Square contribution, then Row Percent, Column Percent, Total Percent, and your standardized residual.\n",
    "\n",
    "---\n",
    "\n",
    "### Check Assumption of Expected Frequencies\n",
    "\n",
    "You will want to look in the second row in each cell to find the expected frequency.  Ideally, you want to have the expected value greater than 5 for each cell, but that's a pipe dream typically.  You are technically allowed to have 20% of your cells with 5 or less, as long as none of them are zero. Luckily, you have no zeros here, and it looks like although there are some cells that have values less than five, only 6/30 have that, which happens to be 20%! So you are golden, and meet the assumption for Chi-Square.  You can now proceed to interpret your results!\n",
    "\n",
    "---\n",
    "\n",
    "### Interpret Results\n",
    "\n",
    "The results are shown at the bottom of your output, under the heading ```Pearson's Chi-squared test```.  If the *p* value is less than .05, than this analysis is significant, meaning that age does in fact make a difference in how people rank Episode I. \n",
    "\n",
    "---\n",
    "\n",
    "## Post Hocs\n",
    "\n",
    "You may be wondering HOW age influences rankings for Episode I.  The way you can do this is through a *post hoc* analysis, which will help you determine where those differences lie.  With a Chi-Square, the way you will interpret your significant findings with a post hoc is with the standardized residual, which is located on the very bottom of the cell.   As a general rule, anything that has a standardized residual with an absolute value greater than or equal to two is significantly different than what you expected. It is greater than expected if there is a plus sign, and it is less than expected if there is a minus sign. Looking at the results above, you can see the following: \n",
    "\n",
    "* More people who did not disclose their age ranked Episode I first than expected\n",
    "* More people aged over 60 ranked Episode I first than expected\n",
    "* Fewer people aged over 60 ranked Episode I fifth or sixth than expected\n",
    "* More people aged 18-29 ranked Episode I fifth or sixth than expected\n",
    "* Fewer people aged 30-44 ranked Episode I first than expected\n",
    "* More people aged 30-44 ranked Episode I sixth than expected\n",
    "* Fewer people aged 45-60 ranked Episode I sixth than expected\n",
    "\n",
    "Now, if you were to write this all out and present upon it at a business, you will get laughed out of the house, or even worse, completely ignored.  So you'll need to summarize things and put them in layman's terms. Maybe something like this: \n",
    "\n",
    "```text\n",
    "People either loved or hated Episode I.  Those who did not disclose their age, those who were 30-44 or over 60 years old were more likely to rank Episode I as their favorite. Those over 45 years old were less likely to to rank Episode I as their least favorite, and those over 60 years old were less likely to rank Episode I fifth. Those in the 30-44 year old age group were more likely to rank Episode I last, however.\n",
    "```\n",
    "\n",
    "<div class=\"panel panel-danger\">\n",
    "    <div class=\"panel-heading\">\n",
    "        <h3 class=\"panel-title\">Caution!</h3>\n",
    "    </div>\n",
    "    <div class=\"panel-body\">\n",
    "        <p>You will only look at standardized residuals if your Chi-Square is significant overall! Otherwise you may be reporting spurious data.</p>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453b76be",
   "metadata": {},
   "source": [
    "<hr style=\"height:10px;border-width:0;color:gray;background-color:gray\">\n",
    "\n",
    "# Page 7 - Goodness of Fit Chi-Squares in R<a class=\"anchor\" id=\"DS105L3_page_7\"></a>\n",
    "\n",
    "[Back to Top](#DS105L3_toc)\n",
    "\n",
    "<hr style=\"height:10px;border-width:0;color:gray;background-color:gray\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af02af4b",
   "metadata": {},
   "source": [
    "# Goodness of Fit Chi-Squares in R\n",
    "\n",
    "You will use a goodness of fit Chi-Square when you are trying to compare a sample to a population.  It is similar in concept to the single sample *t*-test.\n",
    "\n",
    "---\n",
    "\n",
    "## Load in Libraries\n",
    "\n",
    "To compute a goodness of fit Chi-Square, the only package you will need is ```dplyr```, to count up your data.\n",
    "\n",
    "```{r}\n",
    "library(\"dplyr\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Load in Data\n",
    "\n",
    "You will use the same Star Wars data set as you did on the previous page.  It is available **[here again](https://repo.exeterlms.com/documents/V2/DataScience/Intermediate-Stats/SW_survey_renamed.zip)** for your convenience.\n",
    "\n",
    "---\n",
    "\n",
    "## Question Set Up\n",
    "\n",
    "You found something online that mentioned that 90% of people are Star Wars fans, and you want to see if that holds true in your own survey.  In this way, you are comparing your sample (the survey) to the population at large (what you read online). \n",
    "\n",
    "---\n",
    "\n",
    "## Data Wrangling\n",
    "\n",
    "In order to run a goodness of fit Chi-Square, you need the observed values for folks who are fans of Star Wars, and for folks who are not fans of Star Wars. You can easily get those values by aggregating your data using the ```dplyr``` ```summarize()``` function for count (```n()```): \n",
    "\n",
    "```{r}\n",
    "SW_survey_renamed %>% group_by(FanYN) %>% summarize(count=n())\n",
    "```\n",
    "\n",
    "And here are the results: \n",
    "\n",
    "```text\n",
    "  FanYN count\n",
    "  <fct> <int>\n",
    "1 \"\"      350\n",
    "2 No      284\n",
    "3 Yes     552\n",
    "```\n",
    "\n",
    "You can ignore the missing values in this case, but you'll want to take note of the number of ```No```s and the number of ```Yes```s. \n",
    "\n",
    "---\n",
    "\n",
    "## Run Analysis\n",
    "\n",
    "Now you are ready to set up for your analysis! \n",
    "\n",
    "You will want to define the observed values as vectors, which you got from above: \n",
    "\n",
    "```{r}\n",
    "observed = c(552, 284)\n",
    "```\n",
    "\n",
    "Next, you will define a vector of your expected values.  These expected values must equal 1.  If they don't, you end up with this error when you eventually run your Chi-Square:\n",
    "\n",
    "```text\n",
    "Error in chisq.test(x = observed, p = expected) : \n",
    "  probabilities must sum to 1.\n",
    "```\n",
    "\n",
    "Here is how you will define your expected values. Since you are comparing to the online estimate of 90% Star Wars fans, you will want the Star Wars fans to come first (to match the above, which started with the number of yesses) and you will change 90% to .90: \n",
    "\n",
    "```{r}\n",
    "expected = c(0.90, 0.10)\n",
    "```\n",
    "\n",
    "And now you are ready to run the analysis itself, with the function ```chisq.test()```, in which you will define the argument of ```x=``` with your ```observed``` frequencies, and in which you will define the argument of ```p=``` with your expected frequencies:\n",
    "\n",
    "```{r}\n",
    "chisq.test(x = observed, p = expected)\n",
    "```\n",
    "\n",
    "Here are the results from this goodness of fit Chi-Square: \n",
    "\n",
    "```text\n",
    "\tChi-squared test for given probabilities\n",
    "\n",
    "data:  observed\n",
    "X-squared = 533.76, df = 1, p-value < 2.2e-16\n",
    "```\n",
    "\n",
    "If the *p* value is less than .05, than your observed and expected values differ. In this case, this means that the number of Star Wars fans is not 90%. You might conclude, then, that your sample is somewhat confused compared to the overall population.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adbe654",
   "metadata": {},
   "source": [
    "<hr style=\"height:10px;border-width:0;color:gray;background-color:gray\">\n",
    "\n",
    "# Page 8 - Goodness of Fit Chi-Squares in Python<a class=\"anchor\" id=\"DS105L3_page_8\"></a>\n",
    "\n",
    "[Back to Top](#DS105L3_toc)\n",
    "\n",
    "<hr style=\"height:10px;border-width:0;color:gray;background-color:gray\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c77b9b",
   "metadata": {},
   "source": [
    "# Goodness of Fit Chi-Squares in Python\n",
    "\n",
    "Running a goodness of fit Chi-Square in Python is very similar to running a goodness of fit Chi-Square in R. \n",
    "\n",
    "---\n",
    "\n",
    "## Import Packages\n",
    "\n",
    "You will need the package ```pandas``` to read in your data, and ```scipy``` to run the analysis: \n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import scipy, scipy.stats\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Load in Data\n",
    "\n",
    "You'll work on the same Star Wars survey as you did in R. For your convenience, **[here it is again](https://repo.exeterlms.com/documents/V2/DataScience/Intermediate-Stats/SW_survey_renamed.zip)**. \n",
    "\n",
    "---\n",
    "\n",
    "## Question Set Up\n",
    "\n",
    "You will be testing the same premise as when you did a goodness of fit Chi-Square in R: You found something online that mentioned that 90% of people are Star Wars fans, and you want to see if that holds true in your own survey.  In this way, you are comparing your sample (the survey) to the population at large (what you read online). \n",
    "\n",
    "---\n",
    "\n",
    "## Data Wrangling\n",
    "\n",
    "You will need to get the number of people who were and were not fans of Star Wars.  Luckily, this is relatively easy to do with the ```pandas``` function ```value_counts()```: \n",
    "\n",
    "```python\n",
    "SW.FanYN.value_counts()\n",
    "```\n",
    "\n",
    "And here are the results: \n",
    "\n",
    "```text\n",
    "Yes    552\n",
    "No     284\n",
    "Name: FanYN, dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Run the Analysis\n",
    "\n",
    "Now you are ready to run your analysis! You will first create a variable that houses the observed values: \n",
    "\n",
    "```python\n",
    "observed_values = scipy.array([552, 284])\n",
    "```\n",
    "\n",
    "Then you will create a variable that houses the expected values.  Unlike R, Python requires you to have raw numbers, not percentages here, so you will ned to calculate the values yourself.  First, add up your expected values to get the total: 552 + 284 = 836.  Then, multiply that number by .9 to get what percentage would be 90%. The number is 752 - this becomes your first expected value.  Then subtract hat number, 752, from the total, and you will get your other value: 836-752 = 84. \n",
    "\n",
    "```python\n",
    "expected_values = scipy.array([752, 84])\n",
    "```\n",
    "\n",
    "Once you have those two variables, it is simply a matter of plugging them into your ```chisquare()``` function that comes in ```scipy.stats```: \n",
    "\n",
    "```python\n",
    "scipy.stats.chisquare(observed_values, f_exp=expected_values)\n",
    "```\n",
    "\n",
    "And the output is provided below.  The one labeled ```statistic``` is your Chi-Square value, and the one labeled ```pvalue``` is - suprise, surprise~ - your *p* value! \n",
    "\n",
    "```text\n",
    "Power_divergenceResult(statistic=529.3819655521784, pvalue=3.849512370977756e-117)\n",
    "```\n",
    "\n",
    "It will most likely be written in scientific notation. It is in this case, and so this means that this value is extremely significant - you are moving the decimal over to the left 117 times, which means that there are 116 zeros in front of that 3! And remember that a significant goodness of fit Chi-Square means that your sample significantly differs from the population in some way.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152c538a",
   "metadata": {},
   "source": [
    "<hr style=\"height:10px;border-width:0;color:gray;background-color:gray\">\n",
    "\n",
    "# Page 9 - McNemar Chi-Squares<a class=\"anchor\" id=\"DS105L3_page_9\"></a>\n",
    "\n",
    "[Back to Top](#DS105L3_toc)\n",
    "\n",
    "<hr style=\"height:10px;border-width:0;color:gray;background-color:gray\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073ab3fe",
   "metadata": {},
   "source": [
    "# McNemar Chi-Squares\n",
    "\n",
    "The McNemar Chi-Square is used when you are trying to look at something over time, and have only two timepoints; maybe a pre and a post. The timepoints are your independent variable. You are also limited to two levels of your dependent variable. You can think of a McNemar Chi-Square like a dependent *t*-test for categorical data.\n",
    "\n",
    "---\n",
    "\n",
    "## Load in Libraries\n",
    "\n",
    "In order to complete McNemar Chi-Squares in R, the only libraries you will need are ```gmodels``` to conduct the Chi-Square, and ```tidyr``` to do some data wrangling (though you might not always need to wrangle your data). \n",
    "\n",
    "```{r}\n",
    "library(\"gmodels\")\n",
    "library(\"tidyr\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Load in Data\n",
    "\n",
    "**[The data you'll be using ](https://repo.exeterlms.com/documents/V2/DataScience/Intermediate-Stats/bakery_sales.zip)** comes from the sales records of a bakery.  It has the date and time of each bakery item sold.\n",
    "\n",
    "---\n",
    "\n",
    "## Question Set Up\n",
    "\n",
    "You will be answering the following question: \n",
    "\n",
    "```Do the sales of coffee change from the beginning of the month to the end of the month?```\n",
    "\n",
    "---\n",
    "\n",
    "## Data Wrangling\n",
    "\n",
    "Looking at your data, you will find that you only have a single ```Date``` variable, and that you only have a single ```Item``` variable.  ```Date``` is not broken up yet into the beginning and the end of the month, and ```Item``` is not broken into coffee or other.  So, you will need to do a bit of recoding! \n",
    "\n",
    "---\n",
    "\n",
    "### Check the Structure of Your Data\n",
    "\n",
    "First, it's always a good idea to check the structure of your data. You can use the ```str()``` function to do so: \n",
    "\n",
    "```{r}\n",
    "str(bakery_sales)\n",
    "```\n",
    "\n",
    "And here is the result: \n",
    "\n",
    "```text\n",
    "> str(bakery_sales)\n",
    "'data.frame':\t21293 obs. of  4 variables:\n",
    " $ Date       : Factor w/ 159 levels \"1/1/2017\",\"1/10/2017\",..: 31 31 31 31 31 31 31 31 31 31 ...\n",
    " $ Time       : Factor w/ 8240 levels \"1:21:05\",\"10:00:04\",..: 8216 86 86 120 120 120 130 207 207 207 ...\n",
    " $ Transaction: int  1 2 2 3 3 3 4 5 5 5 ...\n",
    " $ Item       : Factor w/ 95 levels \"Adjustment\",\"Afternoon with the baker\",..: 12 76 76 49 50 27 61 24 67 12 ...\n",
    "```\n",
    "\n",
    "The first thing that you should notice here is that your ```Date``` column is not formatted as a date, and you will need to do that before going farther.  \n",
    "\n",
    "---\n",
    "\n",
    "### Reformatting to a Date\n",
    "\n",
    "Reformatting to a date can be done with the function ```as.Date()```: \n",
    "\n",
    "```{r}\n",
    "bakery_sales$DateR <- as.Date(bakery_sales$Date, format=\"%m/%d/%Y\")\n",
    "```\n",
    "\n",
    "You can specify that this be a new variable by putting a new name at the front before the ```<-```, and then you'll use the function ```as.Date()```. Specify the original variable you are formatting as a date, and then you'll need to use the argument ```format=``` to specify how the date has come in.  Remember that the format needs to match the data exactly.  The ```%m``` is for a decimal month, the ```%d``` is for a decimal day, and the ```%Y``` is for a four-digit year.  You will notice that they are all separated by a ```/``` because that is how the data are separated in the orginal column.\n",
    "\n",
    "---\n",
    "\n",
    "### Separating the Pieces of the Date Variable\n",
    "\n",
    "Once that is done, you will want to separate this out, so that you can look at and recode the ```Day``` column individually.  You'll utilize the ```separate()``` function from the ```tidyr``` package: \n",
    "\n",
    "```{r}\n",
    "bakery_sales1 <- separate(bakery_sales, DateR, c(\"Year\", \"Month\", \"Day\"), sep=\"-\")\n",
    "```\n",
    "\n",
    "And the result is that you now have month, day, and year, all split out in your dataset.\n",
    "\n",
    "----\n",
    "\n",
    "### Recoding to Beginning or End of Month\n",
    "\n",
    "Now that you have ```Day``` separated from the pack, you can see to the recoding: \n",
    "\n",
    "```{r}\n",
    "bakery_sales1$DayR <- NA\n",
    "bakery_sales1$DayR[bakery_sales1$Day <= 15] <- 0\n",
    "bakery_sales1$DayR[bakery_sales1$Day > 15] <- 1\n",
    "```\n",
    "\n",
    "This code first opens up a new variable named ```DayR```, and then splits the content in half.  Anything that is on the 15th of the month or earlier is recoded as a zero, while anything on the 16th of the month or later will be recoded as a one.\n",
    "\n",
    "---\n",
    "\n",
    "### Recoding to Coffee or Other\n",
    "\n",
    "The last recode you have left to undertake is to recode the ```Item``` variable from listing every single item out to recoding into the discrete categories of coffee or not coffee. Below, you'll find code that creates a new variable named ```CoffeeSales``` and fills it with a 1 for anything that is ```Coffee``` and fills it with a 0 for anything that is not coffee.\n",
    "\n",
    "```{r}\n",
    "bakery_sales1$CoffeeSales <- NA\n",
    "bakery_sales1$CoffeeSales[bakery_sales1$Item == \"Coffee\"] <- 1\n",
    "bakery_sales1$CoffeeSales[bakery_sales1$Item != \"Coffee\"] <- 0\n",
    "```\n",
    "\n",
    "And with that, you are now ready to launch into your assumption testing and analysis!\n",
    "\n",
    "---\n",
    "\n",
    "## Test Assumptions and Run Analyses\n",
    "\n",
    "The assumptions for a McNemar Chi-Square is the same as for an independent Chi-Square: you need to have at least 5 expected observations in each cell.  And just like the independent Chi-Square, in R, you will need to run the entire analysis first and then check the assumption.  All the code is nearly the same, too, except that you will add in the argument of ```mcnemar=TRUE```.  Take a look: \n",
    "\n",
    "```{r}\n",
    "CrossTable(bakery_sales1$DayR, bakery_sales1$CoffeeSales, fisher=TRUE, chisq = TRUE, mcnemar = TRUE, expected = TRUE, sresid=TRUE, format=\"SPSS\")\n",
    "```\n",
    "\n",
    "And here are the results you will receive: \n",
    "\n",
    "```text\n",
    "\n",
    "   Cell Contents\n",
    "|-------------------------|\n",
    "|                   Count |\n",
    "|         Expected Values |\n",
    "| Chi-square contribution |\n",
    "|             Row Percent |\n",
    "|          Column Percent |\n",
    "|           Total Percent |\n",
    "|            Std Residual |\n",
    "|-------------------------|\n",
    "\n",
    "Total Observations in Table:  21293 \n",
    "\n",
    "                   | bakery_sales1$CoffeeSales \n",
    "bakery_sales1$DayR |        0  |        1  | Row Total | \n",
    "-------------------|-----------|-----------|-----------|\n",
    "                 0 |     8238  |     2841  |    11079  | \n",
    "                   | 8232.374  | 2846.626  |           | \n",
    "                   |    0.004  |    0.011  |           | \n",
    "                   |   74.357% |   25.643% |   52.031% | \n",
    "                   |   52.067% |   51.928% |           | \n",
    "                   |   38.689% |   13.342% |           | \n",
    "                   |    0.062  |   -0.105  |           | \n",
    "-------------------|-----------|-----------|-----------|\n",
    "                 1 |     7584  |     2630  |    10214  | \n",
    "                   | 7589.626  | 2624.374  |           | \n",
    "                   |    0.004  |    0.012  |           | \n",
    "                   |   74.251% |   25.749% |   47.969% | \n",
    "                   |   47.933% |   48.072% |           | \n",
    "                   |   35.617% |   12.351% |           | \n",
    "                   |   -0.065  |    0.110  |           | \n",
    "-------------------|-----------|-----------|-----------|\n",
    "      Column Total |    15822  |     5471  |    21293  | \n",
    "                   |   74.306% |   25.694% |           | \n",
    "-------------------|-----------|-----------|-----------|\n",
    "\n",
    " \n",
    "Statistics for All Table Factors\n",
    "\n",
    "\n",
    "Pearson's Chi-squared test \n",
    "------------------------------------------------------------\n",
    "Chi^2 =  0.03119586     d.f. =  1     p =  0.8598041 \n",
    "\n",
    "Pearson's Chi-squared test with Yates' continuity correction \n",
    "------------------------------------------------------------\n",
    "Chi^2 =  0.02589738     d.f. =  1     p =  0.8721512 \n",
    "\n",
    " \n",
    "McNemar's Chi-squared test \n",
    "------------------------------------------------------------\n",
    "Chi^2 =  2157.894     d.f. =  1     p =  0 \n",
    "\n",
    "McNemar's Chi-squared test with continuity correction \n",
    "------------------------------------------------------------\n",
    "Chi^2 =  2156.985     d.f. =  1     p =  0 \n",
    "\n",
    " \n",
    "Fisher's Exact Test for Count Data\n",
    "------------------------------------------------------------\n",
    "Sample estimate odds ratio:  1.00556 \n",
    "\n",
    "Alternative hypothesis: true odds ratio is not equal to 1\n",
    "p =  0.8629243 \n",
    "95% confidence interval:  0.9450908 1.06987 \n",
    "\n",
    "Alternative hypothesis: true odds ratio is less than 1\n",
    "p =  0.5762927 \n",
    "95% confidence interval:  0 1.059359 \n",
    "\n",
    "Alternative hypothesis: true odds ratio is greater than 1\n",
    "p =  0.4360365 \n",
    "95% confidence interval:  0.9545028 Inf \n",
    "\n",
    "\n",
    " \n",
    "       Minimum expected frequency: 2624.374 \n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Check Assumption of Expected Frequencies\n",
    "\n",
    "In order to meet the assumption for the McNemar Chi-Square, you will need to have at least 5 expected per cell. With the lowest expected value being in the two thousands, you have definitely met this assumption! \n",
    "\n",
    "---\n",
    "\n",
    "## Interpret Results\n",
    "\n",
    "You will start by looking at the *p* value for ```McNemar's Chi-squared test```.  It doesn't usually matter whether you look at the original or the one with the continuity correction - they are usually pretty close. If the *p* value is less than .05, then this test is significant.  This means that on this occasion, there is a difference in coffee sales from the beginning to the end of the month.  \n",
    "\n",
    "---\n",
    "\n",
    "## Post Hocs\n",
    "\n",
    "What does that difference actually look like? Well that's a matter for post hocs, and again, like the independent Chi-Square, you will examine the standardized residuals.  Anything with an absolute value of 2 (can be positive or negative) differs from expected.  However, looking at your post hocs (which have been corrected to account for the possibility of Type I error), you find that none of your standardized residuals are over 2.  This means that this test was not really significant after all.  A good litmus test for this is to look at your row total percentages.  See how sales at the beginning of the month are at 52%, and sales at the beginning of the month are 48%? Although these are technically different, they're pretty darn close, and the test has decided that they are similar enough that it is not significant.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff86da3",
   "metadata": {},
   "source": [
    "<hr style=\"height:10px;border-width:0;color:gray;background-color:gray\">\n",
    "\n",
    "# Page 10 - McNemar Chi-Square Python<a class=\"anchor\" id=\"DS105L3_page_10\"></a>\n",
    "\n",
    "[Back to Top](#DS105L3_toc)\n",
    "\n",
    "<hr style=\"height:10px;border-width:0;color:gray;background-color:gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159fc6cc",
   "metadata": {},
   "source": [
    "# McNemar Chi-Square Python\n",
    "\n",
    "You will now learn how to conduct McNemar Chi-Squares in Python.  The process is much the same, but the output leaves something to be desired. \n",
    "\n",
    "---\n",
    "\n",
    "## Load in Packages\n",
    "\n",
    "In order to run McNemar Chi-Squares in Python, you will need ```pandas``` to read in your data, and ```statsmodels``` to analyze it: \n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import statsmodels as sm\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Load in Data\n",
    "\n",
    "You will be using **[the same bakery data as you did with R](https://repo.exeterlms.com/documents/V2/DataScience/Intermediate-Stats/bakery_sales.zip)**. It has the date and time of each bakery item sold.\n",
    "\n",
    "---\n",
    "\n",
    "## Question Set Up\n",
    "\n",
    "You will be answering the following question: \n",
    "\n",
    "```Do the sales of coffee change from the beginning of the month to the end of the month?```\n",
    "\n",
    "---\n",
    "\n",
    "## Data Wrangling\n",
    "\n",
    "Just like with R, you will need to do some data wrangling.  \n",
    "\n",
    "---\n",
    "\n",
    "### Separating the Pieces of the Date Variable\n",
    "\n",
    "\n",
    "The first order of business is to separate out your ```Date``` column. You can do this with the function ```str.split()```: \n",
    "\n",
    "```python\n",
    "bakery1 = bakery['Date'].str.split('/', expand=True).rename(columns = lambda x: \"Date\" + str(x +1))\n",
    "```\n",
    "\n",
    "And then of course you'll need to put your data back together again: \n",
    "\n",
    "```python\n",
    "bakery3 = pd.concat([bakery, bakery1], axis=1)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Changing Day to an Integer\n",
    "\n",
    "Next you'll need to recode the ```Date2``` variable so that it provides information about beginning or ending of the month. To do this, your ```Date2``` variable will need to be an integer.  You can double check that it is with the function ```info()```: \n",
    "\n",
    "```python\n",
    "bakery3.info()\n",
    "```\n",
    "\n",
    "And here is the result: \n",
    "\n",
    "```text\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 21293 entries, 0 to 21292\n",
    "Data columns (total 7 columns):\n",
    "Date           21293 non-null object\n",
    "Time           21293 non-null object\n",
    "Transaction    21293 non-null int64\n",
    "Item           21293 non-null object\n",
    "Date1          21293 non-null object\n",
    "Date2          21293 non-null object\n",
    "Date3          21293 non-null object\n",
    "dtypes: int64(1), object(6)\n",
    "memory usage: 1.1+ MB\n",
    "```\n",
    "\n",
    "So it looks like ```Date2``` is currently string data, which is common after doing the ```str.split()``` function - after all, it literally translates into \"string split!\" However, this is an easy fix - you can use the ```astype(int)``` function: \n",
    "\n",
    "```python\n",
    "bakery3.Date2 = bakery3.Date2.astype(int)\n",
    "```\n",
    "\n",
    "And now if you run ```info()``` again, you will find that ```Date2``` is now an integer!\n",
    "\n",
    "```text\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 21293 entries, 0 to 21292\n",
    "Data columns (total 7 columns):\n",
    "Date           21293 non-null object\n",
    "Time           21293 non-null object\n",
    "Transaction    21293 non-null int64\n",
    "Item           21293 non-null object\n",
    "Date1          21293 non-null object\n",
    "Date2          21293 non-null int32\n",
    "Date3          21293 non-null object\n",
    "dtypes: int32(1), int64(1), object(5)\n",
    "memory usage: 1.1+ MB\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Recoding to Beginning or End of Month\n",
    "\n",
    "Now that your variable is numeric, you are good to do a recode using the greater than and less than operands.  You can recode using a function with some if statements, and then apply that function to your data: \n",
    "\n",
    "```python\n",
    "def month (series): \n",
    "    if series <= 15: \n",
    "        return 0\n",
    "    if series > 16: \n",
    "        return 1\n",
    "bakery3['DayR'] = bakery3[\"Date2\"].apply(month)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Recoding to Coffee or Other\n",
    "\n",
    "Next, you will recode the ```Item``` variable into something that is Coffee or Not Coffee. You will use the same format as the recode above: \n",
    "\n",
    "```python\n",
    "def item (series): \n",
    "    if series == \"Coffee\": \n",
    "        return 1\n",
    "    if series != \"Coffee\": \n",
    "        return 0\n",
    "bakery3['CoffeeYN'] = bakery3[\"Item\"].apply(item)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Make a Contingency Table\n",
    "\n",
    "Next, you will need to make a contingency table, since the function for McNemar Chi-Squares in Python will not accept raw data.  Happily, the ```pd.crosstab()``` function you learned earlier will do this job easily for you: \n",
    "\n",
    "```python\n",
    "bakery_crosstab = pd.crosstab(bakery3['DayR'], bakery3['CoffeeYN'])\n",
    "bakery_crosstab\n",
    "```\n",
    "\n",
    "![A table has two rows and two columns. The column headings represent coffeeYN and the headings are labeled 0 and 1. The row headings represent Day R and the headings are labeled 0.0 and 1.0. The row entries as follows. Row 1, 8238, 2841. Row 2, 7126,2491.](Media/chi1.png)\n",
    "\n",
    "---\n",
    "\n",
    "## Test Assumptions and Run Analyses\n",
    "\n",
    "In Python, there is no way to test the assumption of at least five expected per cell, which means that if you are analyzing high stakes data, where accuracy really matters, Python is NOT the program for you to run a McNemar Chi-Square in.  \n",
    "\n",
    "You will use the function ```sm.stats.contingency_tables.mcnemar()``` to run your McNemar Chi-Square.  It takes the arguments of the crosstab you just created, ```exact=```, which you can set to ```False```, and ```correction=```, which will be set to ```True```. \n",
    "\n",
    "```python\n",
    "result = sm.stats.contingency_tables.mcnemar(bakery_crosstab, exact=False, correction=True)\n",
    "```\n",
    "\n",
    "If you just run the code above, you may end up confused - nothing happened! That's because this particular function requires you to actually print your results out yourself: \n",
    "\n",
    "```python\n",
    "print(result)\n",
    "```\n",
    "\n",
    "And with that, it will now provide output:\n",
    "\n",
    "```text\n",
    "pvalue      0.0\n",
    "statistic   1841.3420286946925\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Interpret Results\n",
    "\n",
    "Alright! You now have results, and they are significant - the *p* value is less than .05, so it looks like different amounts of coffee is sold in the morning and afternoon! How does it differ? With Python, you'll NEVER KNOW! It does not provide the ability to look at standardized residuals, so you can't look at post hocs. \n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "Although continuous data is usually easier to work with and you can extract more data from it, there will be times when you come up against a large pile of categorical data (especially if your company collected it themselves!) and you will need some advanced categorical analysis tools in your arsenal! You will use one proportion testing when you are comparing the rate of one item to a gold standard rate.  Two proportion testing will be used to compare rates between items to a gold standard rate.  Goodness of fit Chi-Squares are used to test whether your sample data could feasibly come from the population as a whole, and you can use a McNemar Chi-Square to look at anything that is repeatedly measured that has two categorical variables. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448e07db",
   "metadata": {},
   "source": [
    "<hr style=\"height:10px;border-width:0;color:gray;background-color:gray\">\n",
    "\n",
    "# Page 11 - Key Terms<a class=\"anchor\" id=\"DS105L3_page_11\"></a>\n",
    "\n",
    "[Back to Top](#DS105L3_toc)\n",
    "\n",
    "<hr style=\"height:10px;border-width:0;color:gray;background-color:gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363d3b8f",
   "metadata": {},
   "source": [
    "# Key Terms\n",
    "\n",
    "Below is a list and short description of the important keywords learned in this lesson. Please read through and go back and review any concepts you do not fully understand. Great Work!\n",
    "\n",
    "<table class=\"table table-striped\">\n",
    "    <tr>\n",
    "        <th>Keyword</th>\n",
    "        <th>Description</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"font-weight: bold;\" nowrap>One proportion testing</td>\n",
    "        <td>Compare the proportion of two things.</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "---\n",
    "\n",
    "## Key R Libraries\n",
    "\n",
    "<table class=\"table table-striped\">\n",
    "    <tr>\n",
    "        <th>Keyword</th>\n",
    "        <th>Description</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"font-weight: bold;\" nowrap>gmodels</td>\n",
    "        <td>Used for Chi-Squares.</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "---\n",
    "\n",
    "## Key R Code\n",
    "\n",
    "<table class=\"table table-striped\">\n",
    "    <tr>\n",
    "        <th>Keyword</th>\n",
    "        <th>Description</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"font-weight: bold;\" nowrap>prop.test()</td>\n",
    "        <td>Conducts a one and two proportions test.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"font-weight: bold;\" nowrap>x=</td>\n",
    "        <td>An argument for prop.test() where you will specify the sample size of the first object you are comparing.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"font-weight: bold;\" nowrap>n=</td>\n",
    "        <td>An argument for prop.test() where you will specify the sample size of the second object you are comparing.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"font-weight: bold;\" nowrap>alternative=</td>\n",
    "        <td>An argument for prop.test() where you will specify whether the alternative hypothesis is one-tailed or two-tailed. Values are \"two.sided\", \"less\", or \"greater.\"</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"font-weight: bold;\" nowrap>CrossTable()</td>\n",
    "        <td>Creates Chi-Squares from raw data.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"font-weight: bold;\" nowrap>fisher=</td>\n",
    "        <td>An argument for the CrossTable() function that provides effect size when marked TRUE. </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"font-weight: bold;\" nowrap>chisq=</td>\n",
    "        <td>An argument for CrossTable() that provides the Chi-Square statistic when marked TRUE.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"font-weight: bold;\" nowrap>expected=</td>\n",
    "        <td>An argument for CrossTable() that provides expected frequencies in the output when marked TRUE.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"font-weight: bold;\" nowrap>sresid=</td>\n",
    "        <td>An argument for CrossTable() that provides standardized residuals, but does not print them when marked TRUE.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"font-weight: bold;\" nowrap>format=\"SPSS\"</td>\n",
    "        <td>An argument for CrossTable() that will print out standardized residuals in the output.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"font-weight: bold;\" nowrap>chisq.test()</td>\n",
    "        <td>Creates goodness of fit Chi-Squares.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"font-weight: bold;\" nowrap>mcnemar=</td>\n",
    "        <td>An argument for CrossTable() that computes a McNemar Chi-Square when marked TRUE. Can only be used with a 2x2 data grid.</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "---\n",
    "\n",
    "## Key Python Packages\n",
    "\n",
    "<table class=\"table table-striped\">\n",
    "    <tr>\n",
    "        <th>Keyword</th>\n",
    "        <th>Description</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"font-weight: bold;\" nowrap>statsmodels.stats.proportion </td>\n",
    "        <td>To get the proportions testing functions.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"font-weight: bold;\" nowrap>numpy</td>\n",
    "        <td>To make arrays.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"font-weight: bold;\" nowrap>scipy</td>\n",
    "        <td>A package containing various statistical functions.</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "---\n",
    "\n",
    "## Key Python Code\n",
    "\n",
    "<table class=\"table table-striped\">\n",
    "    <tr>\n",
    "        <th>Keyword</th>\n",
    "        <th>Description</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"font-weight: bold;\" nowrap>proportions_ztest()</td>\n",
    "        <td>Conducts one and two proportion tests.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"font-weight: bold;\" nowrap>np.array()</td>\n",
    "        <td>Creates an array.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"font-weight: bold;\" nowrap>scipy.array()</td>\n",
    "        <td>Creates an array formatted for use with the scipy package.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"font-weight: bold;\" nowrap>scipy.stats.chisquare()</td>\n",
    "        <td>Creates goodness of fit Chi-Squares.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"font-weight: bold;\" nowrap>sm.stats.contingency_tables.mcnemar()</td>\n",
    "        <td>Performs a McNemar Chi-Square.</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a367f0f1",
   "metadata": {},
   "source": [
    "<hr style=\"height:10px;border-width:0;color:gray;background-color:gray\">\n",
    "\n",
    "# Page 12 - Lesson 3 Hands-On <a class=\"anchor\" id=\"DS105L3_page_12\"></a>\n",
    "\n",
    "[Back to Top](#DS105L3_toc)\n",
    "\n",
    "<hr style=\"height:10px;border-width:0;color:gray;background-color:gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32955050",
   "metadata": {},
   "source": [
    "For this Hands On, you will be analyzing bank loan data in R.  \n",
    "\n",
    "<div class=\"panel panel-danger\">\n",
    "    <div class=\"panel-heading\">\n",
    "        <h3 class=\"panel-title\">Caution!</h3>\n",
    "    </div>\n",
    "    <div class=\"panel-body\">\n",
    "        <p>Do not submit your project until you have completed all requirements, as you will not be able to resubmit.</p>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## Requirements\n",
    "\n",
    "This hands on uses a dataset about bank loan data. It is located **[here](https://repo.exeterlms.com/documents/V2/DataScience/Intermediate-Stats/loans.zip)**. There is also **[a data dictionary to help you determine what variables to use](https://repo.exeterlms.com/documents/V2/DataScience/Intermediate-Stats/loans_dictionary.zip)**.\n",
    "\n",
    "For each part, check and correct for assumptions if possible, perform the appropriate categorical data analysis in R, and provide a one-sentence conclusion at the bottom of your program files about the analysis you performed. \n",
    "\n",
    "<div class=\"panel panel-success\">\n",
    "    <div class=\"panel-heading\">\n",
    "        <h3 class=\"panel-title\">Additional Info!</h3>\n",
    "    </div>\n",
    "    <div class=\"panel-body\">\n",
    "        <p>You may want to watch <a href=\"https://vimeo.com/443263319\">this recorded live workshop </a> before beginning the hands-on, which goes over a similar example.</p>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "### Part I\n",
    "\n",
    "Please answer the following question.\n",
    "\n",
    ">Does the term of the loan influence loan status? If so, how? \n",
    "\n",
    "---\n",
    "\n",
    "### Part II\n",
    "\n",
    "Please answer the following question.\n",
    "\n",
    ">How has the ability to own a home changed after 2009? \n",
    "\n",
    "<div class=\"panel panel-info\">\n",
    "    <div class=\"panel-heading\">\n",
    "        <h3 class=\"panel-title\">Tip!</h3>\n",
    "    </div>\n",
    "    <div class=\"panel-body\">\n",
    "        <p><b>To reformat the Date column into a new column, use this code:</b>\n",
    "\n",
    "```{r}\n",
    "loans$DateR <- as.Date(paste(loans$Date), \"%m/%d/%Y\")\n",
    "```\n",
    "<b>Solution to push to Woz-U solution repo:</b>\n",
    "```{r}\n",
    "library(\"gmodels\")\n",
    "library(\"tidyr\")\n",
    "\n",
    "loans$DateR <- as.Date(paste(loans$Date), \"%m/%d/%Y\")\n",
    "\n",
    "loans1 <- separate(loans, DateR, c(\"Year\", \"Month\", \"Day\"), sep=\"-\")\n",
    "\n",
    "loans1$YearR <- NA\n",
    "loans1$YearR[loans1$Year <= 2009] <- 0\n",
    "loans1$YearR[loans1$Year > 2009] <- 1\n",
    "\n",
    "loans1$RentvOwn <- NA\n",
    "loans1$RentvOwn[loans1$home_ownership == \"RENT\"] <- 0\n",
    "loans1$RentvOwn[loans1$home_ownership == \"OWN\"] <- 1\n",
    "\n",
    "CrossTable(loans1$RentvOwn, loans1$YearR, fisher=TRUE, chisq = TRUE, mcnemar = TRUE, expected = TRUE, sresid=TRUE, format=\"SPSS\") \n",
    "```\n",
    "</p>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Part III\n",
    "\n",
    "Please answer the following question.\n",
    "\n",
    "> The news just ran a story that only 15% of homes are fully paid for in America, and that another 10% have given up on paying it back, so the bank has \"charged off\" the loan.  Does it seem likely that the data for this hands on came from the larger population of America?  \n",
    "\n",
    "<div class=\"panel panel-danger\">\n",
    "    <div class=\"panel-heading\">\n",
    "        <h3 class=\"panel-title\">Caution!</h3>\n",
    "    </div>\n",
    "    <div class=\"panel-body\">\n",
    "        <p>Be sure to zip and submit your entire directory when finished!</p>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2bb031-8f87-4868-a862-4bd9502b2e99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
