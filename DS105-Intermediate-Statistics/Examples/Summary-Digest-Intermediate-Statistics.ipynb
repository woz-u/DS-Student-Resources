{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7916ded4",
   "metadata": {},
   "source": [
    "# Summary / Essentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3693045b",
   "metadata": {},
   "source": [
    "## Lesson 1\n",
    "\n",
    "\n",
    "A **single-sample t-test** is meant to examine whether **a particular value is different than the population mean**.   \n",
    "*Example:* A dataset witha continuous variable is given and a single value to test against the entire dataset for significant difference.\n",
    "\n",
    "An **independent t test** is used when you have one independent variable that is categorical and a grouping variable, and one dependent continuous variable. Use an **independent *t*-test** when you want to determine whether the **means of two different, unrelated groups are the same or different**.   \n",
    "*Example:* Variable Car Class with compact and large cars. Question: Do compact and large cars consume the same amount of gaz? Solution: Car Class is one variable with elements of both groups (compact and large) --> first extract these two groups in separate datsets along with the gaz-consumption information. Then run the t-test of these two datasets on the gaz consumption field.\n",
    "\n",
    "**Dependent t-tests** are used when your **samples are related in some way**, but you still want to see if the **means change**. *Example:* The same variables in different years or locations to compare against each other.\n",
    "\n",
    "An **independent Chi-Square** is used when you want to **determine whether two categorical variables influence each other**. Works with a *contingency table*. *Example:* in one dataset cars do tyre size and vehicle size influence each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecafea95",
   "metadata": {},
   "source": [
    "## Lesson 2\n",
    "\n",
    "Transform non-normal distributed data in normal distributed data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09195ea5",
   "metadata": {},
   "source": [
    "\n",
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th><img src=\"../Media/skewedness.png\" width=\"300\"></th>\n",
    "    <th><img src=\"../Media/skew3.png\" width=\"300\"></th>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "<img src=\"../Media/DataTransformationTypes.png\" width=\"500\">\n",
    "\n",
    "Which method to apply depending on how the data is distributed (cf. graph):\n",
    "<img src=\"../Media/DataTransformationTypesExamples.png\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebaf96b",
   "metadata": {},
   "source": [
    "## Lesson 3\n",
    "### One Proportion Testing\n",
    "One proportion testing is used when you want to see whether the proportion of two things are similar.\n",
    "\n",
    "Example: An Easter basket full of candy, which is filled with both jellybeans and chocolate eggs. A random sample of 43 pieces of candy are taken from the Easter basket. There are 15 jellybeans and 28 chocolate eggs in the sample. You can use the function prop.test() to determine the probability that there are the same number of jellybeans as there are chocolates, meaning the proportion of jelly beans and chocolate eggs is equal to 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f1323c",
   "metadata": {},
   "source": [
    "### Two Proportion Testing\n",
    "You will use a two proportion z test when you want to compare the proportions of two different categories to the whole.\n",
    "\n",
    "Example: As an example, you will go back to your Easter basket full of candy, which is filled with both jelly beans and chocolate eggs. Each are available in several colors, and With a two proportion test, you can determine whether the proportions of those candies to the whole differ, as well as whether the proportion of the pink candies differ.\n",
    "There are 15 jelly beans and 28 chocolate eggs. Of the jelly beans, 7 are pink. Of the chocolate eggs, 12 are pink.\n",
    "\n",
    "```{r}\n",
    "prop.test(x = c(7, 12), n = c(15, 28),\n",
    "          alternative = \"two.sided\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122e60bb",
   "metadata": {},
   "source": [
    "### Chi Square\n",
    "There are two assumptions associated with independent Chi-Squares. The first is that you need to have independent data. This is just a theoretical requirement - each person or object must be able to fit in only one cell. The second is that your expected frequencies (i.e. element count) must be greater than 5 for each cell. You will be able to check this second assumption by running your Chi-Square and asking for expected frequencies.\n",
    "\n",
    "```{r}\n",
    "CrossTable(SW_survey_renamed$Age, SW_survey_renamed$RankI, fisher=TRUE, chisq = TRUE, expected = TRUE, sresid=TRUE, format=\"SPSS\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b2393e",
   "metadata": {},
   "source": [
    "### McNemar Chi-Squares\n",
    "The McNemar Chi-Square is used when you are trying to look at something over time, and have only two timepoints; maybe a pre and a post. The timepoints are your independent variable. You are also limited to two levels of your dependent variable. You can think of a McNemar Chi-Square like a dependent t-test for categorical data.\n",
    "\n",
    "Example: is coffee sold more at the beginning or end of the moth (both 0/1 levels!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ac7c24",
   "metadata": {},
   "source": [
    "Summary\n",
    "Although continuous data is usually easier to work with and you can extract more data from it, there will be times when you come up against a large pile of categorical data (especially if your company collected it themselves!) and you will need some advanced categorical analysis tools in your arsenal! \n",
    "\n",
    "You will use **one proportion testing** when you are comparing the rate of one item to a gold standard rate. \n",
    "\n",
    "**Two proportion testing** will be used to compare rates between items to a gold standard rate. \n",
    "\n",
    "**Goodness of fit Chi-Squares** are used to test whether your sample data could feasibly come from the population as a whole, and you can use a **McNemar Chi-Square** to look at anything that is repeatedly measured that has two categorical variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7f6e95",
   "metadata": {},
   "source": [
    "## Lesson 4\n",
    "### ANOVA\n",
    "\n",
    "Steps:\n",
    "*  DataWrangling - bringing data into shape: extracting (e.g. 3 types of Apps out of 15 into separate Dataframe) or making DV numeric\n",
    "*  Test Assumptions\n",
    "    *  Normality of DV\n",
    "        *  Histograms\n",
    "    *  Homogeneity of Variance of DV:\n",
    "        *  Bartlett's test is for when your data is normally distributed\n",
    "        *  Fligner's test is for when your data is non-parametric\n",
    "        *  Correcting for Violations of Homogeneity of Variance: There are two ways that you can correct for a violation of homogeneity of variance. The first is the BoxCox transformation of your data, and the second is running a slightly different type of ANOVA, one that was created specifically to handle this violation. That test is called the Welch One-Way Test, and you'll learn about this ANOVA option.\n",
    "    *  Sample size: ANOVA requires a sample size of at least 20 per independent variable.  \n",
    "    *  Independence: There is no statistical test for the assumption of independence.  \n",
    "       \n",
    "If in Python:\n",
    "If Homegeneity of Variance of DV is not met (p<0.05) then do another analysis:\n",
    "*   stats.f_oneway()\n",
    "*   Post Hoc Test\n",
    "\n",
    "Example: \n",
    "\n",
    "```{r}\n",
    "stats.f_oneway(YTC2['VideoViews5RT'][YTC2['Grade']==0],\n",
    "                   YTC2['VideoViews5RT'][YTC2['Grade']==1],\n",
    "               YTC2['VideoViews5RT'][YTC2['Grade']==2],\n",
    "               YTC2['VideoViews5RT'][YTC2['Grade']==3])\n",
    "```\n",
    "\n",
    "and \n",
    "\n",
    "```{r}\n",
    "postHoc = MultiComparison(YTC2['VideoViews5RT'], YTC2['Grade'])\n",
    "postHocResults = postHoc.tukeyhsd()\n",
    "print(postHocResults)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0146044e",
   "metadata": {},
   "source": [
    "## Lesson 5 \n",
    "### Repeated ANOVA\n",
    "Repeated Measures ANOVAs, also known as within subjects ANOVAs, are when you are measuring the same person or thing repeatedly over time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432829d0",
   "metadata": {},
   "source": [
    "This is an example for R\n",
    "```{r}\n",
    "library(\"rcompanion\")\n",
    "library(\"fastR2\")\n",
    "library(\"car\")\n",
    "\n",
    "# read in data\n",
    "honey <- read.csv(\"Library/Mobile Documents/com~apple~CloudDocs/Privat/Weiterbildung/Bethel-DataScience/Module6_Intermediate_Statistics/DS105-Intermediate-Statistics/Data/honey.csv\")\n",
    "View(honey)\n",
    "str(honey)\n",
    "\n",
    "#Task:\n",
    "#Determine whether honey production totalprod has changed over the years (year) using a repeated measures ANOVA\n",
    "summary(honey)\n",
    "#checking for NULL values\n",
    "sapply(honey, function(x) sum(is.na(x)))\n",
    "\n",
    "#DataWrangling for year:\n",
    "honey$year <- as.character(honey$year)\n",
    "honey$year <- as.factor(honey$year)\n",
    "\n",
    "#Normality\n",
    "plotNormalHistogram(honey$totalprod)\n",
    "#fairly positively skewed --> sqrt\n",
    "honey$totalprodSQRT <- sqrt(honey$totalprod)\n",
    "plotNormalHistogram(honey$totalprodSQRT)\n",
    "#not so nice yet - try log\n",
    "\n",
    "honey$totalprodLog <- log(honey$totalprod)\n",
    "plotNormalHistogram(honey$totalprodLog)\n",
    "#way better!!\n",
    "\n",
    "#Homogeneity of Variance\n",
    "leveneTest(totalprodLog ~ year, data=honey)\n",
    "# Levene's Test for Homogeneity of Variance (center = median)\n",
    "#        Df F value Pr(>F)\n",
    "# group   4  0.0318  0.998\n",
    "#       196\n",
    "#--> no violation of homogeneity of variance!! p=0.998\n",
    "#\n",
    "# Sample Size\n",
    "# A repeated measures ANOVA requires a sample size of at least 20 per independent variable.\n",
    "# We have that, so this assumption has been met.\n",
    "\n",
    "#ANOVA Analysis - globally, not considering a grouping by state:\n",
    "RManova1 <- aov(totalprodLog~year, honey)\n",
    "summary(RManova1)\n",
    "#Result:\n",
    "#               Df Sum Sq Mean Sq F value Pr(>F)\n",
    "# year          4    0.4   0.112   0.058  0.994\n",
    "# Residuals   196  378.0   1.929\n",
    "# There seem to be no significance.\n",
    "# Ergo: Globally in the U.S. honey production has not changed over the years\n",
    "\n",
    "#taking the state as Error into account:\n",
    "RManova2 <- aov(totalprodLog~year+Error(state), honey)\n",
    "summary(RManova2)\n",
    "\n",
    "#Result:\n",
    "# Error: state\n",
    "# Df Sum Sq Mean Sq F value Pr(>F)\n",
    "# year       1    2.6   2.571   0.272  0.605\n",
    "# Residuals 39  368.6   9.452\n",
    "#\n",
    "# Error: Within\n",
    "#              Df  Sum Sq Mean Sq F value  Pr(>F)\n",
    "# year        4    0.677 0.16913   4.007 0.00402 **\n",
    "#   Residuals 156  6.584 0.04221\n",
    "# ---\n",
    "#   Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
    "# This seems significant at 0.01 with 0.00402!\n",
    "# Ergo: Locally, State-wise, in the U.S. honey production has changed over the years.\n",
    "#\n",
    "#Post Hocs\n",
    "pairwise.t.test(honey$totalprodLog, honey$state, p.adjust=\"none\")\n",
    "#This try did not give me any results... probably too few datasets\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d33f49a",
   "metadata": {},
   "source": [
    "## Lesson 6 \n",
    "### Mixed Measures ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2775211",
   "metadata": {},
   "source": [
    "A mixed measure ANOVA includes both a *within* and a *between subject* variable. Follow a very similar process to do a mixed measures ANOVA as a repeated measures or within subjects ANOVA, but an additional factor is added, a second IV.   \n",
    "A sample question:   \n",
    "```text\n",
    "Did those who ate breakfast in the morning improve their resting metabolic rate from baseline to follow up compared to those who skipped breakfast?  \n",
    "```\n",
    "\n",
    "IV:   \n",
    "I     Eating Habit, Categorical, 2 Levels (ate breakfast; no breakfast); ('Treatment.Group')   \n",
    "(II)  Time; Categorical; 2 Levels (Baseline; Followup); ('contrasts')    \n",
    "DV:   resting metabolic rate; ('repdat')\n",
    "\n",
    "**Testing Assumptions** \n",
    "\n",
    "The assumptions for a mixed measure ANOVA are the same as the ones for a repeated measures ANOVA.  The only thing that differs is the sample size, because now there are two IVs. \n",
    "\n",
    "**Sample Size**\n",
    "\n",
    "Must be per IV minimum 20 --> at least 2*20.\n",
    "\n",
    "**Analysis**\n",
    "\n",
    "```text\n",
    "RManova1 <- aov(repdat~(Treatment.Group*contrasts)+Error(Participant.Code/(contrasts)), breakfast6)\n",
    "summary(RManova1)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fd8a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb88483d",
   "metadata": {},
   "source": [
    "## Lesson 7 \n",
    "### ANCOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1e687d",
   "metadata": {},
   "source": [
    "ANCOVA stands for analysis of covariance. It is an analysis in the family of ANOVAs, and the big difference is that \"C.\" An ANCOVA takes into account, or adjusts for, yet another factor in the model, aptly named a **covariate**. Put another way, an ANCOVA controls for the changes that might come up naturally. For instance, men are slightly better than women at spatial and analytic reasoning on average. If you collected information from everyone about their gender, you could then use it to control for the natural differences between men and women, using it as a covariate.\n",
    "\n",
    "Covariates are typically continuous, but it is possible to use categorical covariates if you dummy code them.\n",
    "\n",
    "Example question:\n",
    "\n",
    "```text\n",
    "Controlling for students' research participation in undergrad, does the rating of the students' undergraduate university impact their chance of admittance into graduate school? \n",
    "```\n",
    "\n",
    "IV: University Rating; categroical, 5 Levels   \n",
    "DV: Chance of admittance; continuous   \n",
    "CV: Student's Research Participation; categorical, 2 Levels\n",
    "\n",
    "***Ensure the IV and CV are a Factors***\n",
    "\n",
    "### Testing Assumptions\n",
    "#### homogeneity of regression slopes\n",
    "The assumptions for an ANCOVA are similar to those for your basic ANOVAs. However, one assumption is added - the assumption of homogeneity of regression slopes, which tests for whether the predictor variable (DV) and the covariate are independent of each other. \n",
    "\n",
    "#### Normality\n",
    "Check for Normality of DV\n",
    "\n",
    "```{r}\n",
    "plotNormalHistogram(graduate_admissions$Chance.of.Admit)\n",
    "```\n",
    "\n",
    "#### Homogeneity of Variance\n",
    "\n",
    "```{r}\n",
    "leveneTest(Chance.of.AdmitSQ~University.Rating, data=graduate_admissions)\n",
    "```\n",
    "\n",
    "#### Homogeneity of Regression Slopes\n",
    "\n",
    "In order to test for homogeneity of regression slopes, run a one-way ANOVA, with covariate as the IV and the DV to use for ANCOVA. If the *F* test is non-significant, then you are good to go!\n",
    "\n",
    "Here is the basic ANOVA information: \n",
    "\n",
    "```{r}\n",
    "Homogeneity_RegrSlp = lm(Chance.of.AdmitSQ~Research, data=graduate_admissions)\n",
    "anova(Homogeneity_RegrSlp)\n",
    "```\n",
    "\n",
    "If *p* value is significant, data does not meet the assumption of homogeneity of regression slopes.  That means that CV has an influence on DV and thus should not be used as CV but as another IV in the model.\n",
    "\n",
    "#### Sample Size\n",
    "\n",
    "The last assumption for ANCOVAs is sample size. There has to be at least 20 cases for every IV or CV.\n",
    "\n",
    "\n",
    "#### Violation of Homogeneity of Variance   \n",
    "If you failed the assumption of homogeneity of variance, there is a quick and easy additional line you can add to the base model. Instead of running the anova() function, you can instead run the **Anova()** function. It is a function that corrects for a violation of homogeneity of variance.\n",
    "\n",
    "Here is what using the big A Anova() function looks like:\n",
    "```{r}\n",
    "Anova(ANCOVA, Type=\"I\", white.adjust=TRUE)*\n",
    "```\n",
    "\n",
    "#### Post Hocs\n",
    "\n",
    "\n",
    "```{r}\n",
    "postHocs <- glht(ANCOVA,linfct=mcp(University.Rating = \"Tukey\"))\n",
    "summary(postHocs)\n",
    "```\n",
    "\n",
    "For an ANCOVA, you will still run a post hoc with the Tukey's correction, but you will need to do so using functions from the ```multcomp``` package instead because you now need to handle the covariate and interaction effects.  You will do this using the ```glht()``` function: \n",
    "\n",
    "```{r}\n",
    "postHocs <- glht(ANCOVA,linfct=mcp(University.Rating = \"Tukey\"))\n",
    "summary(postHocs)\n",
    "```\n",
    "\n",
    "The independent variable will go in the second second of parentheses before the equals sign.  ```linfct=mcp``` is standard code that you will use routinely.\n",
    "\n",
    "#### Determine Means and Draw Conclusions \n",
    "\n",
    "Because a covariate is included in the model, it is important to look at **adjusted** means, rather than the raw means.  The means are adjusted by controlling for the covariate.   \n",
    "\n",
    "```{r}\n",
    "adjMeans <- effect(\"University.Rating\", ANCOVA)\n",
    "adjMeans\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2c1c0d",
   "metadata": {},
   "source": [
    "## Lesson 8 \n",
    "### MANOVA\n",
    "\n",
    "#### Assumptions for MANOVA:\n",
    "*  Sample size\n",
    "*  Multivariate Normality\n",
    "*  Homogeneity of Variance\n",
    "*  Absence of Multicollinearity size\n",
    "*  Independence\n",
    "\n",
    "##### Sample Size\n",
    "\n",
    "There must be more cases than dependent variables in every cell.  In addition, there must be at least 20 cases per independent variable, as per ANOVAs.\n",
    "\n",
    "---\n",
    "\n",
    "##### Multivariate Normality\n",
    "\n",
    "The dependent variables need to be normally distributed when they are lumped all together in one uber-variable that will be used for the MANOVA.\n",
    "\n",
    "---\n",
    "\n",
    "##### Homogeneity of Variance \n",
    "\n",
    "Like ANOVAs, the variables being used must have relatively equal variance. \n",
    "\n",
    "---\n",
    "\n",
    "##### Absence of Multicollinearity\n",
    "\n",
    "*Multicollinearity* is when there is a significant relationship between the dependent variables in the model.  It is to be avoided, since having a lot of overlap between DVs can again increase the chances of Type I error; finding a significant relationship between the IV and the DV when one really isn't there. Testing for multicollinearity just requires a correlation matrix, although there are specific statistics designed to test for it as well.\n",
    "\n",
    "---\n",
    "\n",
    "##### Independence\n",
    "\n",
    "The assumption of independence is the same for ANOVAs as it is for MANOVAs. In a nutshell, the different levels of the independent variable should NOT be related to each other! This isn't something typically tested for, but rather assessed by using the user's noggin as they think about the data they are about to analyze.  If there's a chance that a participant or an object will fit into more than one level of the IV, than chances are there is a violation of the assumption of independence and a MANOVA should not be run!\n",
    "\n",
    "---\n",
    "\n",
    "Example Question:   \n",
    "\n",
    "```text\n",
    "Does the country the project originated in influence the number of backers and the amount of money pledged?\n",
    "```\n",
    "\n",
    "#### Data Wrangling\n",
    "\n",
    "Although no data wrangling is actually required for the MANOVA itself, some wrangling is required to test for assumptions. In order to test for multivariate normality, you will need to create a dataset containing **only the two dependent variables** that is in a **matrix** format, and ensure that they are numeric. Unfortunately, the *test for normality can only handle 5,000 records*, so you will also need to limit your data to 5,000 rows as well.\n",
    "\n",
    "---\n",
    "\n",
    "##### Ensure Variables are Numeric\n",
    "\n",
    "And then check the structure of the data to see what format your dependent variables are in.\n",
    "\n",
    "```{r}\n",
    "str(kickstarter$pledged)\n",
    "str(kickstarter$backers)\n",
    "```\n",
    "\n",
    "#### Subsetting \n",
    "\n",
    "Next, keep only the two dependent variabes, e.g. ```pledged``` and ```backers```.\n",
    "\n",
    "```{r}\n",
    "keeps <- c(\"pledged\", \"backers\")\n",
    "kickstarter1 <- kickstarter[keeps]\n",
    "```\n",
    "\n",
    "Then limit the number of rows: \n",
    "\n",
    "```{r}\n",
    "kickstarter2 <- kickstarter1[1:5000,]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Format as a Matrix\n",
    "\n",
    "Lastly, format the data as a matrix: \n",
    "\n",
    "```{r}\n",
    "kickstarter3 <- as.matrix(kickstarter2)\n",
    "```\n",
    "\n",
    "### Test Assumptions\n",
    "#### Multivariate Normality\n",
    "\n",
    "To test for multivariate normality, use the wrangled dataset , ```kickstarter3```, in the Wilks-Shapiro test. Use the function ```mshapiro.test()``` pulled from the ```mvnormtest``` library: \n",
    "\n",
    "```{r}\n",
    "mshapiro.test(t(kickstarter3))\n",
    "```\n",
    "\n",
    "#### Homogeneity of Variance\n",
    "\n",
    "Use Levene's Test from the ```car``` library to test for homogeneity of variance on **both** of your dependent variables: \n",
    "\n",
    "```{r}\n",
    "leveneTest(pledged ~ country, data=kickstarter)\n",
    "leveneTest(backers ~ country, data=kickstarter)\n",
    "```\n",
    "\n",
    "#### Absence of Multicollinearity\n",
    "\n",
    "Typically, multicollinearity can be assessed simply by running correlations of the dependent variables with each other. A general rule of thumb is that anything above approximately .7 for correlation (i.e. a strong correlation) indicates the presence of multicollinearity.  Check out the correlation between ```pledged``` and ```backers``` with a simple ```cor.test()``` function: \n",
    "\n",
    "```{r}\n",
    "cor.test(kickstarter$pledged, kickstarter$backers, method=\"pearson\", use=\"complete.obs\")\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
